{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from scipy.optimize import curve_fit\n",
    "from typing import Dict, Any\n",
    "import recordclass.recordclass as rc\n",
    "from itertools import product\n",
    "\n",
    "if (os.name == 'posix'):\n",
    "    repo_path = r\"/Volumes/C/Public/Users/Hybrid/Repos/Hybrid_H5/H5_python3\"\n",
    "else:\n",
    "    repo_path = r\"C:\\Users\\Hybrid\\Repos\\Hybrid_H5\\H5_python3\"\n",
    "sys.path.append(repo_path)\n",
    "# local imports\n",
    "import HamamatsuH5\n",
    "from Iterations import Iterations,seed_permute\n",
    "from PlottingH5 import default_plotting, iterate_plot_2D\n",
    "from FittingH5 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_subplots(nrows=1, ncols=1,*args,**kwargs):\n",
    "    \"\"\"\n",
    "    Function to wrap plt.subplots and make sure the same block of code can plot many axes and a single axis\n",
    "    \"\"\"\n",
    "    fig,axarr = plt.subplots(nrows,ncols,*args,**kwargs)\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axarr = [axarr]\n",
    "    return fig,axarr\n",
    "    \n",
    "h5file = h5py.File('results.hdf5',mode='r+')\n",
    "\n",
    "iterations = Iterations(h5file)\n",
    "#Find number of measurements per experiment\n",
    "measurements = h5file['settings/experiment/measurementsPerIteration'][()]+1\n",
    "num_its = len(h5file['iterations'])\n",
    "\n",
    "iterations\n",
    "#Find independent variable names and values\n",
    "#indep_vars = DataH5.get_indep_vars(h5file)\n",
    "#iVars = list(indep_vars.keys())\n",
    "\n",
    "# map iterations to independent variable values\n",
    "# iterations = DataH5.make_iterations_df(h5file, iVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create n-darray of iteration numbers\n",
    "* useful when there are multiple independent variables\n",
    "* Indexing is [ivar1,ivar2,ivar3,...,ivarn]\n",
    "* ivar ordering is alphabetical\n",
    "* identical to ordering of keys in indep_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamamatsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ROI\n",
    "fg = HamamatsuH5.set_frame_grabber_region(h5file)\n",
    "width = fg['right']-fg['left']\n",
    "height = fg['bottom']-fg['top']\n",
    "\n",
    "# For documentation try > help(HMROI)\n",
    "roi = HamamatsuH5.HMROI(width,height,dic = {\n",
    "    \"left\" : 2,\n",
    "    \"right\" : 5,\n",
    "    \"top\" : 4,\n",
    "    \"bottom\" : 7\n",
    "})\n",
    "\n",
    "#Load data into memory\n",
    "shots_per_measurement = int(h5file['/settings/experiment/LabView/camera/shotsPerMeasurement/function'][()])\n",
    "# pixel-by-pixel data indexed : [iteration, measurement, shot, y-pixel, x-pixel]\n",
    "hm_pix = HamamatsuH5.load_data(h5file,roi)\n",
    "\n",
    "#take pixel-by-pixel data and treat it into counter data then mean data\n",
    "# \"count\" data indexed : [iteration, measurement, shot]\n",
    "hm_counts = hm_pix.sum(3).sum(3)\n",
    "# mean count data indexed : [iteration, shot]\n",
    "mus = hm_counts.mean(1)\n",
    "# standard deviation in mean indexed : [iteration, shot]\n",
    "ers = hm_counts.std(1)/sqrt(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histograms of count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots = True\n",
    "if plots and len(iterations) > 22:\n",
    "    ans = input(f\"You're about to plot {len(iterations)} histograms. Are you sure you want to do that? (y/N) : \").upper()[0]\n",
    "    plots = ans==\"Y\"\n",
    "if plots:\n",
    "    fig,axarr = plt_subplots(len(iterations),1,figsize=(6,4*len(iterations)))\n",
    "    for iteration, row in iterations.iterrows():\n",
    "        iteration = int(iteration)\n",
    "        for shot in range(shots_per_measurement):\n",
    "            axarr[iteration].hist(hm_counts[iteration,:,shot],histtype='step', label = f\"shot {shot}\",bins=30)\n",
    "        axarr[iteration].legend()\n",
    "        axarr[iteration].set_title(str(row))\n",
    "        fig.tight_layout()\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"You have chosen not to plot the histograms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mean count data\n",
    "* If only 1 iteration : Prints out means for each shot and the corresponding standard deviation\n",
    "* If there is 1 independent variable : Plot means for each iteration with error bars\n",
    "* If there are 2 independent variables : show image of means for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "default_plotting(iterations,mus,ers,shots_per_measurement,description=\"Mean Counts in ROI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D as many 1D\n",
    "\n",
    "* Often, when a 2D scan is performed it's more enlightening to plot each row (or column) of data as a line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterate_plot_2D(**{\n",
    "    \"iterations\": iterations,\n",
    "    \"data\": mus,\n",
    "    \"data_error\": ers,\n",
    "    \"description\": \"Counts in ROI\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images taken within ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show average image for one shot for each iteration\n",
    "im_shot = 0 # shot to image\n",
    "\n",
    "fig,axarr = plt_subplots(len(iterations),1,figsize=(6,4*len(iterations)))\n",
    "for index, row in iterations.iterrows():\n",
    "    iteration = row['iteration']\n",
    "    axarr[iteration].imshow(hm_pix[iteration,:,im_shot,:,:].mean(0))\n",
    "    axarr[iteration].set_title(str(row))\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histgram data of each picture for each iteration\n",
    "* Very memory hungry!\n",
    "* Please clear output before saving, copying or pushing if this cell was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_width = roi.right-roi.left\n",
    "im_height = roi.bottom-roi.top\n",
    "for iteration, row in iterations.iterrows():\n",
    "    i = row['iteration']\n",
    "    fig,axarr = plt.subplots(im_height,im_width,figsize = (10,10))\n",
    "    for y in range(im_height):\n",
    "        for x in range(im_width):\n",
    "            bns = 20\n",
    "            for shot in range(shots_per_measurement):\n",
    "                axarr[y,x].hist(hm_pix[i,:,shot,y,x],bins=bns,histtype='step',label = f\"Shot {shot}\")\n",
    "            axarr[y,x].set_title(f\"x = {x}, y = {y}\")\n",
    "            axarr[y,x].legend()\n",
    "    fig.suptitle(str(row))\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_data = hm_counts\n",
    "shot_to_fit = 1\n",
    "\n",
    "func = double_gaussian\n",
    "guess = {\n",
    "    \"mu1\": 22560,\n",
    "    \"mu2\": 27000,\n",
    "    \"std1\": 500,\n",
    "    \"std2\": 2000,\n",
    "    \"a1\": 2000,\n",
    "    \"a2\": 1000\n",
    "}\n",
    "\n",
    "for i, row in iterations.iterrows():\n",
    "    iteration = row['iteration']\n",
    "    bns = 30\n",
    "    hist, bin_edges = histogram(count_data[iteration,:,shot_to_fit],bins=bns)\n",
    "    \n",
    "    popt,pcov = curve_fit(f=func,xdata = bin_edges[1:], ydata = hist, p0 = list(guess.values()))\n",
    "    perr = sqrt(diag(pcov))  # uncertainty in fit parameters\n",
    "    \n",
    "    cut = gauss_intercept(*popt)\n",
    "    cut_err = cut_err_gauss(*append(popt,perr))\n",
    "    \n",
    "    print(f\"cut_err: {cut_err}\")\n",
    "    cut_h = cut+cut_err\n",
    "    cut_l = cut-cut_err\n",
    "    \n",
    "    for i,var in enumerate(guess):\n",
    "        exec(f\"{var} = {popt[i]}\")\n",
    "        exec(f\"d{var} = {perr[i]}\")\n",
    "        \n",
    "    \n",
    "    ovlp = gauss_discrimination_error(cut,*popt)\n",
    "    \n",
    "    xln = linspace(min(count_data[iteration,:,shot_to_fit]),max(count_data[iteration,:,shot_to_fit]),1000)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.hist(count_data[iteration,:,1],bins=bns,histtype='step',label = f\"Hist\")\n",
    "    ax.plot(xln,func(xln,*popt),label=f\"Fit\")\n",
    "    ax.plot(xln,gaussian(xln,*popt[0::2]),label=f\"0 atom\")\n",
    "    ax.plot(xln,gaussian(xln,*popt[1::2]),label=f\"1 atom\")\n",
    "    ax.axvline(cut)\n",
    "    ax.axvline(cut_l)\n",
    "    ax.axvline(cut_h)\n",
    "    ax.set_title(f\"mu1 : {mu1:.0f} $\\pm$ {dmu1:.0f} | mu2 : {mu2:.0f} $\\pm$ {dmu2:.0f}\\n cut : {cut:.0f} $\\pm$ {cut_err:.0f}\\n overlap: {ovlp:.3f}\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    print(f\"Overlap : {ovlp}\")\n",
    "    print(f\"cut : {cut}\\ncut_err : {cut_err}\")\n",
    "    print(f\"popt : {popt}\\nperr : {perr}\\npcov : {pcov}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def shot_error(probability: float,samples: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        probability : number between 0 and 1. Measured probability of an event occurring \n",
    "        samples : number of samples used to measure the ratio\n",
    "    Returns:\n",
    "        shot noise uncertainty. Uncertainty in probability due to statistical variations\n",
    "    \"\"\"\n",
    "    return sqrt(probability*(1-probability)/samples)\n",
    "\n",
    "shots = 2\n",
    "\n",
    "# Set count data variable, so this works regadless of device\n",
    "count_data = hm_counts\n",
    "cut = 24000  # 0 atom - 1 atom cut\n",
    "multi_cut = 40000  # 1 atom - multi atom cut\n",
    "\n",
    "zero_loading = (count_data < cut).sum(1)/measurements\n",
    "zero_loading_error_bar = shot_error(zero_loading, measurements)\n",
    "multi_loading = (count_data > multi_cut).sum(1)/measurements\n",
    "multi_loading_error_bar = shot_error(multi_loading, measurements)\n",
    "single_loading = 1-(zero_loading+multi_loading)\n",
    "single_loading_error_bar = shot_error(single_loading, measurements)\n",
    "multi_to_single_loading = multi_loading/single_loading\n",
    "multi_to_single_loading_error_bar = sqrt(multi_loading_error_bar**2 + single_loading_error_bar**2)\n",
    "\n",
    "loadings = {\n",
    "    0: \"Zero\",\n",
    "    1: \"Single\",\n",
    "    2: \"Multi\",\n",
    "    3: \"Multi_to_Single\"\n",
    "}\n",
    "\n",
    "for num,name in loadings.items():\n",
    "    rate = eval(f\"{name.lower()}_loading\")\n",
    "    rate_error_bar = eval(f\"{name.lower()}_loading_error_bar\")\n",
    "    default_plotting(iterations,rate,rate_error_bar,shots=shots,description = f\"{name} atom loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_error(probability: float,samples: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        probability : number between 0 and 1. Measured probability of an event occurring \n",
    "        samples : number of samples used to measure the ratio\n",
    "    Returns:\n",
    "        shot noise uncertainty. Uncertainty in probability due to statistical variations\n",
    "    \"\"\"\n",
    "    return sqrt(probability*(1-probability)/samples)\n",
    "\n",
    "shots = 2\n",
    "\n",
    "# Set count data variable, so this works regadless of device\n",
    "count_data = hm_counts\n",
    "cut = 24000  # 0 atom - 1 atom cut\n",
    "multi_cut = 40000  # 1 atom - multi atom cut\n",
    "\n",
    "single_loading = (count_data < multi_cut)*(count_data > cut)  # Measurements that were loaded\n",
    "retained = single_loading[...,1]*single_loading[...,0]  # Measurements that were retained\n",
    "loaded = single_loading[...,0].sum(1)  # Number of loaded measurements in each iteration\n",
    "\n",
    "retention = retained.sum(1)/loaded\n",
    "retention_error_bar = shot_error(retention,loaded)\n",
    "\n",
    "default_plotting(iterations,retention,retention_error_bar,description = \"Retention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to next results folder\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import operator\n",
    "from numpy import sort\n",
    "\n",
    "volume = os.getcwd()[0]\n",
    "analysis_fname = 'Analysis3.ipynb'\n",
    "measurement_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir_filter = lambda f : os.path.isdir(f)\n",
    "\n",
    "# If the latest experiment folder already has an analysis file, should that be overwritten?\n",
    "override = True\n",
    "\n",
    "# find latest day folder created by cspy\n",
    "daily_folders = list(filter(\n",
    "    dir_filter,\n",
    "    [os.path.join(measurement_path,f) for f in os.listdir(measurement_path)]\n",
    "))  # make sure non-folder names are not listed\n",
    "today_path = sort(daily_folders)[-1]\n",
    "print(today_path)\n",
    "#find all experiments taken on the last day\n",
    "experiments_today = list(filter(\n",
    "    dir_filter,\n",
    "    [os.path.join(today_path,f) for f in os.listdir(today_path)]\n",
    "))\n",
    "#and the last experiment taken the last day\n",
    "last_experiment = sort(experiments_today)[-1]\n",
    "exp_path = os.path.join(today_path, last_experiment)\n",
    "\n",
    "# Copy\n",
    "if analysis_fname not in os.listdir(exp_path) or override:\n",
    "    print(\"Copying {} from :\\n\\t{}\\nto:\\n\\t{}\".format(analysis_fname,os.getcwd(),exp_path))\n",
    "    shutil.copy(os.path.join(os.getcwd(),analysis_fname),exp_path)\n",
    "else:\n",
    "    print(\"Folder {} already have analysis file. If you wish to overwrite that file set 'override' to True\".format(exp_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to Git Repo\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import operator\n",
    "from numpy import sort\n",
    "\n",
    "volume = os.getcwd()[0]\n",
    "analysis_fname = 'Analysis3.ipynb'\n",
    "measurement_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir_filter = lambda f : os.path.isdir(f)\n",
    "\n",
    "# If the latest experiment folder already has an analysis file, should that be overwritten?\n",
    "override = True\n",
    "\n",
    "# Copy\n",
    "if analysis_fname not in os.listdir(repo_path) or override:\n",
    "    print(f\"Copying {analysis_fname} from :\\n\\t{os.getcwd()}\\nto:\\n\\t{repo_path}\")\n",
    "    shutil.copy(os.path.join(os.getcwd(),analysis_fname),repo_path)\n",
    "else:\n",
    "    print(f\"Folder {repo_path} already have analysis file. If you wish to overwrite that file set 'override' to True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
